# LLM API Keys (optional if using a non-Anthropic model)
ANTHROPIC_API_KEY=sk-ant-your-key-here

# LLM Configuration
LITELLM_MODEL=claude-sonnet-4-20250514
# LITELLM_MODEL=ollama/llama3.1  # Uncomment to use local model
# LITELLM_BASE_URL=http://host.docker.internal:11434  # Example for local gateways

# Obsidian Configuration
OBSIDIAN_API_KEY=your-obsidian-rest-api-key-here
OBSIDIAN_VAULT_PATH=/Users/yourname/Documents/ObsidianVault
OBSIDIAN_URL=http://host.docker.internal:27123

# Database
POSTGRES_PASSWORD=choose-a-secure-password-here

# Ollama (local embeddings, running natively)
OLLAMA_URL=http://host.docker.internal:11434

# Internal Service URLs (set automatically by docker-compose)
QDRANT_URL=http://qdrant:6333
REDIS_URL=redis://redis:6379
SIGNAL_API_URL=http://signal-api:8080
DATABASE_URL=postgresql://brain:choose-a-secure-password-here@postgres:5432/brain

# Signal Configuration
SIGNAL_PHONE_NUMBER=+15551234567  # Your registered Signal number for the agent
ALLOWED_SENDERS='["+15559876543","+15551112222"]'  # Required: JSON list of allowed senders; empty = deny all

# Conversation Storage
CONVERSATION_FOLDER=Brain/Conversations  # Obsidian path for conversation logs
SUMMARY_EVERY_TURNS=7  # Write a summary every N assistant turns (0 disables); 7 came from a quick sample where ~4k chars covered about 6-8 turns.

# Code-Mode / UTCP
UTCP_CONFIG_PATH=~/.config/brain/utcp.json
CODE_MODE_TIMEOUT=30

# User Context
USER=yourname
